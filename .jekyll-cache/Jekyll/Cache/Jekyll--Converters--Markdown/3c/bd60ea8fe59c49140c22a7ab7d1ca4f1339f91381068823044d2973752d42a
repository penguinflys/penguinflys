I"5<blockquote>
  <p>Abstract: In this post, we are going to look deep into policy gradient, why it works, and many new policy gradient algorithms proposed in recent years: vanilla policy gradient, actor-critic, off-policy actor-critic, A3C, A2C, DPG, DDPG, MADDPG, TRPO, PPO, ACER, and ACTKR.</p>
</blockquote>
:ET