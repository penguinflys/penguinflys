I"®µ<blockquote>
  <p>In this series of posts on ‚ÄúObject Recognition for Dummies‚Äù, we will go through several basic concepts, algorithms, and popular deep learning models for image processing and objection detection. Hopefully, it would be a good read for people with no experience in this field but want to learn more. The Part 1 introduces the concept of Gradient Vectors, the HOG (Histogram of Oriented Gradients) algorithm, and Selective Search for image segmentation.</p>
</blockquote>

<!--more-->

<p>I‚Äôve never worked in the field of computer vision and has no idea how the magic could work when an autonomous car is configured to tell apart a stop sign from a pedestrian in a red hat. To motivate myself to look into the maths behind object recognition algorithms, I‚Äôm writing a few posts on this topic ‚ÄúObject Recognition for Dummies‚Äù. This post, part 1, starts with super rudimentary concepts in image processing and a few methods for image segmentation. Nothing related to deep neural networks yet. Deep learning models for object recognition will be discussed in <a href="/2017/12/16/object-recognition-for-dummies-part-2.html">Part 2</a> and <a href="/2018/01/01/object-recognition-for-dummies-part-3.html">Part 3</a>.</p>

<ul class="table-of-content" id="markdown-toc">
  <li><a href="#image-gradient-vector" id="markdown-toc-image-gradient-vector">Image Gradient Vector</a>    <ul>
      <li><a href="#common-image-processing-kernels" id="markdown-toc-common-image-processing-kernels">Common Image Processing Kernels</a></li>
      <li><a href="#example-manu-in-2004" id="markdown-toc-example-manu-in-2004">Example: Manu in 2004</a></li>
    </ul>
  </li>
  <li><a href="#histogram-of-oriented-gradients-hog" id="markdown-toc-histogram-of-oriented-gradients-hog">Histogram of Oriented Gradients (HOG)</a>    <ul>
      <li><a href="#how-hog-works" id="markdown-toc-how-hog-works">How HOG works</a></li>
      <li><a href="#example-manu-in-2004-1" id="markdown-toc-example-manu-in-2004-1">Example: Manu in 2004</a></li>
    </ul>
  </li>
  <li><a href="#image-segmentation-felzenszwalbs-algorithm" id="markdown-toc-image-segmentation-felzenszwalbs-algorithm">Image Segmentation (Felzenszwalb‚Äôs Algorithm)</a>    <ul>
      <li><a href="#graph-construction" id="markdown-toc-graph-construction">Graph Construction</a></li>
      <li><a href="#key-concepts" id="markdown-toc-key-concepts">Key Concepts</a></li>
      <li><a href="#how-image-segmentation-works" id="markdown-toc-how-image-segmentation-works">How Image Segmentation Works</a></li>
      <li><a href="#example-manu-in-2013" id="markdown-toc-example-manu-in-2013">Example: Manu in 2013</a></li>
    </ul>
  </li>
  <li><a href="#selective-search" id="markdown-toc-selective-search">Selective Search</a>    <ul>
      <li><a href="#how-selective-search-works" id="markdown-toc-how-selective-search-works">How Selective Search Works</a></li>
      <li><a href="#configuration-variations" id="markdown-toc-configuration-variations">Configuration Variations</a></li>
    </ul>
  </li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>

<h2 id="image-gradient-vector">Image Gradient Vector</h2>

<p>First of all, I would like to make sure we can distinguish the following terms. They are very similar, closely related, but not exactly the same.</p>

<table class="info">
  <tbody>
    <tr>
      <td>¬†</td>
      <td><strong>Derivative</strong></td>
      <td><strong>Directional Derivative</strong></td>
      <td><strong>Gradient</strong></td>
    </tr>
    <tr>
      <td>Value type</td>
      <td>Scalar</td>
      <td>Scalar</td>
      <td>Vector</td>
    </tr>
    <tr>
      <td>Definition</td>
      <td>The rate of change of a function \(f(x,y,z,...)\) at a point \((x_0,y_0,z_0,...)\), which is the slope of the tangent line at the point.</td>
      <td>The instantaneous rate of change of \(f(x,y,z, ...)\) in the direction of an unit vector \(\vec{u}\).</td>
      <td>It points in the direction of the greatest rate of increase of the function, containing all the partial derivative information of a multivariable function.</td>
    </tr>
  </tbody>
</table>

<p>In the image processing, we want to know the direction of colors changing from one extreme to the other (i.e. black to white on a grayscale image). Therefore, we want to measure ‚Äúgradient‚Äù on pixels of colors. The gradient on an image is discrete because each pixel is independent and cannot be further split.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Image_gradient">image gradient vector</a> is defined as a metric for every individual pixel, containing the pixel color changes in both x-axis and y-axis. The definition is aligned with the gradient of a continuous multi-variable function, which is a vector of partial derivatives of all the variables. Suppose f(x, y) records the color of the pixel at location (x, y), the gradient vector of the pixel (x, y) is defined as follows:</p>

\[\begin{align*}
\nabla f(x, y)
= \begin{bmatrix}
  g_x \\
  g_y
\end{bmatrix}
= \begin{bmatrix}
  \frac{\partial f}{\partial x} \\[6pt]
  \frac{\partial f}{\partial y}
\end{bmatrix}
= \begin{bmatrix}
  f(x, y+1) - f(x, y-1)\\
  f(x+1, y) - f(x-1, y)
\end{bmatrix}
\end{align*}\]

<p>The \(\frac{\partial f}{\partial x}\) term is the partial derivative on the x-direction, which is computed as the color difference between the adjacent pixels on the left and right of the target, f(x, y+1) - f(x, y-1). Similarly, the \(\frac{\partial f}{\partial y}\) term is the partial derivative on the y-direction, measured as f(x+1, y) - f(x-1, y), the color difference between the adjacent pixels above and below the target.</p>

<p>There are two important attributes of an image gradient:</p>
<ul>
  <li><strong>Magnitude</strong> is the L2-norm of the vector, \(g = \sqrt{ g_x^2 + g_y^2 }\).</li>
  <li><strong>Direction</strong> is the arctangent of the ratio between the partial derivatives on two directions, \(\theta = \arctan{(g_y / g_x)}\).</li>
</ul>

<p style="width: 420px;" class="center"><img src="/assets/images/image-gradient-vector-pixel-location.png" alt="Pixels for Gradient Vector" /></p>
<p><em>Fig. 1. To compute the gradient vector of a target pixel at location (x, y), we need to know the colors of its four neighbors (or eight surrounding pixels depending on the kernel).</em></p>

<p>The gradient vector of the example in Fig. 1. is:</p>

\[\begin{align*}
\nabla f 
= \begin{bmatrix}
  f(x, y+1) - f(x, y-1)\\
  f(x+1, y) - f(x-1, y)
\end{bmatrix}
= \begin{bmatrix}
  90-40\\
  55-105
\end{bmatrix}
= \begin{bmatrix}
  50\\
  -50
\end{bmatrix}
\end{align*}\]

<p>Thus,</p>
<ul>
  <li>the magnitude is \(\sqrt{50^2 + (-50)^2} = 22.3607\), and</li>
  <li>the direction is \(\arctan{(-50/50)} = -45^{\circ}\).</li>
</ul>

<p>Repeating the gradient computation process for every pixel iteratively is too slow. Instead, it can be well translated into applying a convolution operator on the entire image matrix, labeled as \(\mathbf{A}\) using one of the specially designed convolutional kernels.</p>

<p>Let‚Äôs start with the x-direction of the example in Fig 1. using the kernel \({[-1,0,1]}^{-1}\) sliding over the x-axis; \(\ast\) is the convolution operator:</p>

\[\begin{align*}
\mathbf{G}_x &amp;= 
\begin{bmatrix}
  -1\\
  0\\
  1
\end{bmatrix} \ast [40,255,90] = -40 + 0 + 90 = 50
\end{align*}\]

<p>Similarly, on the y-direction, we adopt the kernel \([-1,0,1]\):</p>

\[\begin{align*}
\mathbf{G}_y &amp;= 
\begin{bmatrix}
  105\\
  255\\
  55
\end{bmatrix} \ast [-1,0,1] = -105 + 0 + 55 = -50
\end{align*}\]

<p>Try this in python:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">scipy.signal</span> <span class="k">as</span> <span class="n">sig</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">105</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">40</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">90</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">55</span><span class="p">,</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">G_x</span> <span class="o">=</span> <span class="n">sig</span><span class="p">.</span><span class="n">convolve2d</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">]]),</span> <span class="n">mode</span><span class="o">=</span><span class="s">'valid'</span><span class="p">)</span> 
<span class="n">G_y</span> <span class="o">=</span> <span class="n">sig</span><span class="p">.</span><span class="n">convolve2d</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]]),</span> <span class="n">mode</span><span class="o">=</span><span class="s">'valid'</span><span class="p">)</span>
</code></pre></div></div>

<p>These two functions return <code class="language-plaintext highlighter-rouge">array([[0, 50, 0]])</code> and <code class="language-plaintext highlighter-rouge">array([[0], [-50], [0]])</code> respectively.</p>

<h3 id="common-image-processing-kernels">Common Image Processing Kernels</h3>

<p><a href="https://en.wikipedia.org/wiki/Prewitt_operator">Prewitt operator</a>: Rather than only relying on four directly adjacent neighbors, the Prewitt operator utilizes eight surrounding pixels for smoother results.</p>

\[\mathbf{G}_x = \begin{bmatrix}
-1 &amp; 0 &amp; +1 \\
-1 &amp; 0 &amp; +1 \\
-1 &amp; 0 &amp; +1
\end{bmatrix} \ast \mathbf{A} \text{ and }
\mathbf{G}_y = \begin{bmatrix}
+1 &amp; +1 &amp; +1 \\
0 &amp; 0 &amp; 0 \\
-1 &amp; -1 &amp; -1
\end{bmatrix} \ast \mathbf{A}\]

<p><a href="https://en.wikipedia.org/wiki/Sobel_operator">Sobel operator</a>: To emphasize the impact of directly adjacent pixels more, they get assigned with higher weights.</p>

\[\mathbf{G}_x = \begin{bmatrix}
-1 &amp; 0 &amp; +1 \\
-2 &amp; 0 &amp; +2 \\
-1 &amp; 0 &amp; +1
\end{bmatrix} \ast \mathbf{A} \text{ and }
\mathbf{G}_y = \begin{bmatrix}
+1 &amp; +2 &amp; +1 \\
0 &amp; 0 &amp; 0 \\
-1 &amp; -2 &amp; -1
\end{bmatrix} \ast \mathbf{A}\]

<p>Different kernels are created for different goals, such as edge detection, blurring, sharpening and many more. Check <a href="https://en.wikipedia.org/wiki/Kernel_(image_processing)">this wiki page</a> for more examples and references.</p>

<h3 id="example-manu-in-2004">Example: Manu in 2004</h3>

<p>Let‚Äôs run a simple experiment on the photo of Manu Ginobili in 2004 [<a href="/assets/data/manu-2004.jpg" target="_blank">Download Image</a>] when he still had a lot of hair. For simplicity, the photo is converted to grayscale first. For colored images, we just need to repeat the same process in each color channel respectively.</p>

<p class="center"><img src="/assets/images/manu-2004.png" alt="Manu 2004" /></p>
<p><em>Fig. 2. Manu Ginobili in 2004 with hair. (Image source: <a href="http://ftw.usatoday.com/2013/05/manu-ginobilis-bald-spot-through-the-years">Manu Ginobili‚Äôs bald spot through the years</a>)</em></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">import</span> <span class="nn">scipy.signal</span> <span class="k">as</span> <span class="n">sig</span>
<span class="c1"># With mode="L", we force the image to be parsed in the grayscale, so it is
# actually unnecessary to convert the photo color beforehand.
</span><span class="n">img</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">misc</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="s">"manu-2004.jpg"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"L"</span><span class="p">)</span>

<span class="c1"># Define the Sobel operator kernels.
</span><span class="n">kernel_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">kernel_y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span>

<span class="n">G_x</span> <span class="o">=</span> <span class="n">sig</span><span class="p">.</span><span class="n">convolve2d</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">kernel_x</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'same'</span><span class="p">)</span> 
<span class="n">G_y</span> <span class="o">=</span> <span class="n">sig</span><span class="p">.</span><span class="n">convolve2d</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">kernel_y</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'same'</span><span class="p">)</span> 

<span class="c1"># Plot them!
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>

<span class="c1"># Actually plt.imshow() can handle the value scale well even if I don't do 
# the transformation (G_x + 255) / 2.
</span><span class="n">ax1</span><span class="p">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">G_x</span> <span class="o">+</span> <span class="mi">255</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">);</span> <span class="n">ax1</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Gx"</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">G_y</span> <span class="o">+</span> <span class="mi">255</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">);</span> <span class="n">ax2</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Gy"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p class="center"><img src="/assets/images/manu-2004-sobel-operator.png" alt="Sobel operator" /></p>
<p><em>Fig. 3. Apply Sobel operator kernel on the example image.</em></p>

<p>You might notice that most area is in gray. Because the difference between two pixel is between -255 and 255 and we need to convert them back to [0, 255] for the display purpose. 
A simple linear transformation (\(\mathbf{G}\) + 255)/2 would interpret all the zeros (i.e., constant colored background shows no change in gradient) as 125 (shown as gray).</p>

<h2 id="histogram-of-oriented-gradients-hog">Histogram of Oriented Gradients (HOG)</h2>

<p>The Histogram of Oriented Gradients (HOG) is an efficient way to extract features out of the pixel colors for building an object recognition classifier. With the knowledge of image gradient vectors, it is not hard to understand how HOG works. Let‚Äôs start!</p>

<h3 id="how-hog-works">How HOG works</h3>

<p>1) Preprocess the image, including resizing and color normalization.</p>

<p>2) Compute the gradient vector of every pixel, as well as its magnitude and direction.</p>

<p>3) Divide the image into many 8x8 pixel cells. In each cell, the magnitude values of these 64 cells are binned and cumulatively added into 9 buckets of unsigned direction (no sign, so 0-180 degree rather than 0-360 degree; this is a practical choice based on empirical experiments). 
<br /><br />
For better robustness, if the direction of the gradient vector of a pixel lays between two buckets, its magnitude does not all go into the closer one but proportionally split between two. For example, if a pixel‚Äôs gradient vector has magnitude 8 and degree 15, it is between two buckets for degree 0 and 20 and we would assign 2 to bucket 0 and 6 to bucket 20. 
<br /><br />
This interesting configuration makes the histogram much more stable when small distortion is applied to the image.</p>

<p style="width: 600px;" class="center"><img src="/assets/images/HOG-histogram-creation.png" alt="Histogram construction" /></p>
<p><em>Fig. 4. How to split one gradient vector‚Äôs magnitude if its degress is between two degree bins. (Image source: https://www.learnopencv.com/histogram-of-oriented-gradients/)</em></p>

<p>4) Then we slide a 2x2 cells (thus 16x16 pixels) block across the image. In each block region, 4 histograms of 4 cells are concatenated into one-dimensional vector of 36 values and then normalized to have an unit weight.
The final HOG feature vector is the concatenation of all the block vectors. It can be fed into a classifier like SVM for learning object recognition tasks.</p>

<h3 id="example-manu-in-2004-1">Example: Manu in 2004</h3>

<p>Let‚Äôs reuse the same example image in the previous section. Remember that we have computed \(\mathbf{G}_x\) and \(\mathbf{G}_y\) for the whole image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">N_BUCKETS</span> <span class="o">=</span> <span class="mi">9</span>
<span class="n">CELL_SIZE</span> <span class="o">=</span> <span class="mi">8</span>  <span class="c1"># Each cell is 8x8 pixels
</span><span class="n">BLOCK_SIZE</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Each block is 2x2 cells
</span>
<span class="k">def</span> <span class="nf">assign_bucket_vals</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">bucket_vals</span><span class="p">):</span>
    <span class="n">left_bin</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">d</span> <span class="o">/</span> <span class="mf">20.</span><span class="p">)</span>
    <span class="c1"># Handle the case when the direction is between [160, 180)
</span>    <span class="n">right_bin</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">d</span> <span class="o">/</span> <span class="mf">20.</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">N_BUCKETS</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">left_bin</span> <span class="o">&lt;</span> <span class="n">right_bin</span> <span class="o">&lt;</span> <span class="n">N_BUCKETS</span>

    <span class="n">left_val</span><span class="o">=</span> <span class="n">m</span> <span class="o">*</span> <span class="p">(</span><span class="n">right_bin</span> <span class="o">*</span> <span class="mi">20</span> <span class="o">-</span> <span class="n">d</span><span class="p">)</span> <span class="o">/</span> <span class="mi">20</span>
    <span class="n">right_val</span> <span class="o">=</span> <span class="n">m</span> <span class="o">*</span> <span class="p">(</span><span class="n">d</span> <span class="o">-</span> <span class="n">left_bin</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span> <span class="o">/</span> <span class="mi">20</span>
    <span class="n">bucket_vals</span><span class="p">[</span><span class="n">left_bin</span><span class="p">]</span> <span class="o">+=</span> <span class="n">left_val</span>
    <span class="n">bucket_vals</span><span class="p">[</span><span class="n">right_bin</span><span class="p">]</span> <span class="o">+=</span> <span class="n">right_val</span>

<span class="k">def</span> <span class="nf">get_magnitude_hist_cell</span><span class="p">(</span><span class="n">loc_x</span><span class="p">,</span> <span class="n">loc_y</span><span class="p">):</span>
    <span class="c1"># (loc_x, loc_y) defines the top left corner of the target cell.
</span>    <span class="n">cell_x</span> <span class="o">=</span> <span class="n">G_x</span><span class="p">[</span><span class="n">loc_x</span><span class="p">:</span><span class="n">loc_x</span> <span class="o">+</span> <span class="n">CELL_SIZE</span><span class="p">,</span> <span class="n">loc_y</span><span class="p">:</span><span class="n">loc_y</span> <span class="o">+</span> <span class="n">CELL_SIZE</span><span class="p">]</span>
    <span class="n">cell_y</span> <span class="o">=</span> <span class="n">G_y</span><span class="p">[</span><span class="n">loc_x</span><span class="p">:</span><span class="n">loc_x</span> <span class="o">+</span> <span class="n">CELL_SIZE</span><span class="p">,</span> <span class="n">loc_y</span><span class="p">:</span><span class="n">loc_y</span> <span class="o">+</span> <span class="n">CELL_SIZE</span><span class="p">]</span>
    <span class="n">magnitudes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cell_x</span> <span class="o">*</span> <span class="n">cell_x</span> <span class="o">+</span> <span class="n">cell_y</span> <span class="o">*</span> <span class="n">cell_y</span><span class="p">)</span>
    <span class="n">directions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arctan</span><span class="p">(</span><span class="n">cell_y</span> <span class="o">/</span> <span class="n">cell_x</span><span class="p">)</span> <span class="o">*</span> <span class="mi">180</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">)</span>

    <span class="n">buckets</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="n">N_BUCKETS</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">bucket_vals</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N_BUCKETS</span><span class="p">)</span>
    <span class="nb">map</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span> <span class="n">assign_bucket_vals</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">bucket_vals</span><span class="p">),</span> 
        <span class="nb">zip</span><span class="p">(</span><span class="n">magnitudes</span><span class="p">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">directions</span><span class="p">.</span><span class="n">flatten</span><span class="p">())</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">bucket_vals</span>

<span class="k">def</span> <span class="nf">get_magnitude_hist_block</span><span class="p">(</span><span class="n">loc_x</span><span class="p">,</span> <span class="n">loc_y</span><span class="p">):</span>
    <span class="c1"># (loc_x, loc_y) defines the top left corner of the target block.
</span>    <span class="k">return</span> <span class="nb">reduce</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">arr1</span><span class="p">,</span> <span class="n">arr2</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">arr1</span><span class="p">,</span> <span class="n">arr2</span><span class="p">)),</span>
        <span class="p">[</span><span class="n">get_magnitude_hist_cell</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="p">[</span><span class="n">loc_x</span><span class="p">,</span> <span class="n">loc_x</span> <span class="o">+</span> <span class="n">CELL_SIZE</span><span class="p">,</span> <span class="n">loc_x</span><span class="p">,</span> <span class="n">loc_x</span> <span class="o">+</span> <span class="n">CELL_SIZE</span><span class="p">],</span>
            <span class="p">[</span><span class="n">loc_y</span><span class="p">,</span> <span class="n">loc_y</span><span class="p">,</span> <span class="n">loc_y</span> <span class="o">+</span> <span class="n">CELL_SIZE</span><span class="p">,</span> <span class="n">loc_y</span> <span class="o">+</span> <span class="n">CELL_SIZE</span><span class="p">],</span>
        <span class="p">)]</span>
    <span class="p">)</span>
</code></pre></div></div>

<p>The following code simply calls the functions to construct a histogram and plot it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Random location [200, 200] as an example.
</span><span class="n">loc_x</span> <span class="o">=</span> <span class="n">loc_y</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">ydata</span> <span class="o">=</span> <span class="n">get_magnitude_hist_block</span><span class="p">(</span><span class="n">loc_x</span><span class="p">,</span> <span class="n">loc_y</span><span class="p">)</span>
<span class="n">ydata</span> <span class="o">=</span> <span class="n">ydata</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">ydata</span><span class="p">)</span>

<span class="n">xdata</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ydata</span><span class="p">))</span>
<span class="n">bucket_names</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N_BUCKETS</span><span class="p">),</span> <span class="n">BLOCK_SIZE</span> <span class="o">*</span> <span class="n">BLOCK_SIZE</span><span class="p">)</span>

<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">ydata</span><span class="p">)</span> <span class="o">==</span> <span class="n">N_BUCKETS</span> <span class="o">*</span> <span class="p">(</span><span class="n">BLOCK_SIZE</span> <span class="o">*</span> <span class="n">BLOCK_SIZE</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">bucket_names</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">ydata</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s">'center'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">bucket_names</span> <span class="o">*</span> <span class="mi">20</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Direction buckets'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Magnitude'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="n">ls</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"HOG of block at [%d, %d]"</span> <span class="o">%</span> <span class="p">(</span><span class="n">loc_x</span><span class="p">,</span> <span class="n">loc_y</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p>In the code above, I use the block with top left corner located at [200, 200] as an example and here is the final normalized histogram of this block. You can play with the code to change the block location to be identified by a sliding window.</p>

<p class="center"><img src="/assets/images/block_histogram.png" alt="Block histogram" /></p>
<p><em>Fig. 5. Demonstration of a HOG histogram for one block.</em></p>

<p>The code is mostly for demonstrating the computation process. There are many off-the-shelf libraries with HOG algorithm implemented, such as <a href="https://github.com/opencv/opencv">OpenCV</a>, <a href="http://simplecv.org/">SimpleCV</a> and <a href="http://scikit-image.org/">scikit-image</a>.</p>

<h2 id="image-segmentation-felzenszwalbs-algorithm">Image Segmentation (Felzenszwalb‚Äôs Algorithm)</h2>

<p>When there exist multiple objects in one image (true for almost every real-world photos), we need to identify a region that potentially contains a target object so that the classification can be executed more efficiently.</p>

<p>Felzenszwalb and Huttenlocher (<a href="http://cvcl.mit.edu/SUNSeminar/Felzenszwalb_IJCV04.pdf">2004</a>) proposed an algorithm for segmenting an image into similar regions using a graph-based approach. It is also the initialization method for Selective Search (a popular region proposal algorithm) that we are gonna discuss later.</p>

<p>Say, we use a undirected graph \(G=(V, E)\) to represent an input image. One vertex \(v_i \in V\) represents one pixel. One edge \(e = (v_i, v_j) \in E\) connects two vertices \(v_i\) and \(v_j\). Its associated weight \(w(v_i, v_j)\) measures the dissimilarity between \(v_i\) and \(v_j\). The dissimilarity can be quantified in dimensions like color, location, intensity, etc. The higher the weight, the less similar two pixels are. A segmentation solution \(S\) is a partition of \(V\) into multiple connected components, \(\{C\}\). Intuitively similar pixels should belong to the same components while dissimilar ones are assigned to different components.</p>

<h3 id="graph-construction">Graph Construction</h3>

<p>There are two approaches to constructing a graph out of an image.</p>
<ul>
  <li><strong>Grid Graph</strong>: Each pixel is only connected with surrounding neighbours (8 other cells in total). The edge weight is the absolute difference between the intensity values of the pixels.</li>
  <li><strong>Nearest Neighbor Graph</strong>: Each pixel is a point in the feature space (x, y, r, g, b), in which (x, y) is the pixel location and (r, g, b) is the color values in RGB. The weight is the Euclidean distance between two pixels‚Äô feature vectors.</li>
</ul>

<h3 id="key-concepts">Key Concepts</h3>

<p>Before we lay down the criteria for a good graph partition (aka image segmentation), let us define a couple of key concepts:</p>
<ul>
  <li><strong>Internal difference</strong>: \(Int(C) = \max_{e\in MST(C, E)} w(e)\), where \(MST\) is the minimum spanning tree of the components. A component \(C\) can still remain connected even when we have removed all the edges with weights &lt; \(Int(C)\).</li>
  <li><strong>Difference between two components</strong>: \(Dif(C_1, C_2) = \min_{v_i \in C_1, v_j \in C_2, (v_i, v_j) \in E} w(v_i, v_j)\). \(Dif(C_1, C_2) = \infty\) if there is no edge in-between.</li>
  <li><strong>Minimum internal difference</strong>: \(MInt(C_1, C_2) = min(Int(C_1) + \tau(C_1), Int(C_2) + \tau(C_2))\), where \(\tau(C) = k / \vert C \vert\) helps make sure we have a meaningful threshold for the difference between components. With a higher \(k\), it is more likely to result in larger components.</li>
</ul>

<p>The quality of a segmentation is assessed by a pairwise region comparison predicate defined for given two regions \(C_1\) and \(C_2\):</p>

\[D(C_1, C_2) = 
\begin{cases}
  \text{True} &amp; \text{ if } Dif(C_1, C_2) &gt; MInt(C_1, C_2) \\
  \text{False} &amp; \text{ otherwise}
\end{cases}\]

<p>Only when the predicate holds True, we consider them as two independent components; otherwise the segmentation is too fine and they probably should be merged.</p>

<h3 id="how-image-segmentation-works">How Image Segmentation Works</h3>

<p>The algorithm follows a bottom-up procedure. Given \(G=(V, E)\) and \(|V|=n, |E|=m\):</p>
<ol>
  <li>Edges are sorted by weight in ascending order, labeled as \(e_1, e_2, \dots, e_m\).</li>
  <li>Initially, each pixel stays in its own component, so we start with \(n\) components.</li>
  <li>Repeat for \(k=1, \dots, m\):
    <ul>
      <li>The segmentation snapshot at the step \(k\) is denoted as \(S^k\).</li>
      <li>We take  the k-th edge in the order, \(e_k = (v_i, v_j)\).</li>
      <li>If \(v_i\) and \(v_j\) belong to the same component, do nothing and thus \(S^k = S^{k-1}\).</li>
      <li>If \(v_i\) and \(v_j\) belong to two different components \(C_i^{k-1}\) and \(C_j^{k-1}\) as in the segmentation \(S^{k-1}\), we want to merge them into one if \(w(v_i, v_j) \leq MInt(C_i^{k-1}, C_j^{k-1})\); otherwise do nothing.</li>
    </ul>
  </li>
</ol>

<p>If you are interested in the proof of the segmentation properties and why it always exists, please refer to the <a href="http://fcv2011.ulsan.ac.kr/files/announcement/413/IJCV(2004)%20Efficient%20Graph-Based%20Image%20Segmentation.pdf">paper</a>.</p>

<p class="center"><img src="/assets/images/image-segmentation-indoor.png" alt="Image segmentation indoor scene" /></p>
<p><em>Fig. 6. An indoor scene with segmentation detected by the grid graph construction in Felzenszwalb‚Äôs graph-based segmentation algorithm (k=300).</em></p>

<h3 id="example-manu-in-2013">Example: Manu in 2013</h3>

<p>This time I would use the photo of old Manu Ginobili in 2013 [<a href="/assets/data/manu-2013.jpg">Image</a>] as the example image when his bald spot has grown up strong. Still for simplicity, we use the picture in grayscale.</p>

<p class="center"><img src="/assets/images/manu-2013.png" alt="Manu 2013" /></p>
<p><em>Fig. 7. Manu Ginobili in 2013 with bald spot. (Image source: <a href="http://ftw.usatoday.com/2013/05/manu-ginobilis-bald-spot-through-the-years">Manu Ginobili‚Äôs bald spot through the years</a>)</em></p>

<p>Rather than coding from scratch, let us apply <a href="http://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.felzenszwalb">skimage.segmentation.felzenszwalb</a> to the image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">skimage.segmentation</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">img2</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">misc</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="s">"manu-2013.jpg"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"L"</span><span class="p">)</span>
<span class="n">segment_mask1</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">segmentation</span><span class="p">.</span><span class="n">felzenszwalb</span><span class="p">(</span><span class="n">img2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">segment_mask2</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">segmentation</span><span class="p">.</span><span class="n">felzenszwalb</span><span class="p">(</span><span class="n">img2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">segment_mask1</span><span class="p">);</span> <span class="n">ax1</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"k=100"</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">segment_mask2</span><span class="p">);</span> <span class="n">ax2</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"k=1000"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">"Felsenszwalb's efficient graph based image segmentation"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p>The code ran two versions of Felzenszwalb‚Äôs algorithms as shown in Fig. 8. The left k=100 generates a finer-grained segmentation with small regions where Manu‚Äôs bald spot is identified. The right one k=1000 outputs a coarser-grained segmentation where regions tend to be larger.</p>

<p class="center"><img src="/assets/images/manu-2013-segmentation.png" alt="Manu 2013 Image Segmentation" /></p>
<p><em>Fig. 8. Felsenszwalb‚Äôs efficient graph-based image segmentation is applied on the photo of Manu in 2013.</em></p>

<h2 id="selective-search">Selective Search</h2>

<p>Selective search is a common algorithm to provide region proposals that potentially contain objects. It is built on top of the image segmentation output and use region-based characteristics (NOTE: not just attributes of a single pixel) to do a bottom-up hierarchical grouping.</p>

<h3 id="how-selective-search-works">How Selective Search Works</h3>

<ol>
  <li>At the initialization stage, apply Felzenszwalb and Huttenlocher‚Äôs graph-based image segmentation algorithm to create regions to start with.</li>
  <li>Use a greedy algorithm to iteratively group regions together:
    <ul>
      <li>First the similarities between all neighbouring regions are calculated.</li>
      <li>The two most similar regions are grouped together, and new similarities are calculated between the resulting region and its neighbours.</li>
    </ul>
  </li>
  <li>The process of grouping the most similar regions (Step 2) is repeated until the whole image becomes a single region.</li>
</ol>

<p style="width: 480px;" class="center"><img src="/assets/images/selective-search-algorithm.png" alt="Selective Search Algorithm" /></p>
<p><em>Fig. 9. The detailed algorithm of Selective Search.</em></p>

<h3 id="configuration-variations">Configuration Variations</h3>

<p>Given two regions \((r_i, r_j)\), selective search proposed four complementary similarity measures:</p>
<ul>
  <li><strong>Color</strong> similarity</li>
  <li><strong>Texture</strong>: Use algorithm that works well for material recognition such as <a href="http://www.cs.ubc.ca/~lowe/papers/iccv99.pdf">SIFT</a>.</li>
  <li><strong>Size</strong>: Small regions are encouraged to merge early.</li>
  <li><strong>Shape</strong>: Ideally one region can fill the gap of the other.</li>
</ul>

<p>By (i) tuning the threshold \(k\) in Felzenszwalb and Huttenlocher‚Äôs algorithm, (ii) changing the color space and (iii) picking different combinations of similarity metrics, we can produce a diverse set of Selective Search strategies. The version that produces the region proposals with best quality is configured with (i) a mixture of various initial segmentation proposals, (ii) a blend of multiple color spaces and (iii) a combination of all similarity measures. Unsurprisingly we need to balance between the quality (the model complexity) and the speed.</p>

<hr />

<p><em>If you notice mistakes and errors in this post, don‚Äôt hesitate to contact me at [lilian dot wengweng at gmail dot com] and I would be super happy to correct them right away!</em></p>

<p>See you in the next post :D</p>

<h2 id="references">References</h2>

<p>[1] Dalal, Navneet, and Bill Triggs. <a href="https://hal.inria.fr/file/index/docid/548512/filename/hog_cvpr2005.pdf">‚ÄúHistograms of oriented gradients for human detection.‚Äù</a> Computer Vision and Pattern Recognition (CVPR), 2005.</p>

<p>[2] Pedro F. Felzenszwalb, and Daniel P. Huttenlocher. <a href="http://cvcl.mit.edu/SUNSeminar/Felzenszwalb_IJCV04.pdf">‚ÄúEfficient graph-based image segmentation.‚Äù</a> Intl. journal of computer vision 59.2 (2004): 167-181.</p>

<p>[3] <a href="https://www.learnopencv.com/histogram-of-oriented-gradients/">Histogram of Oriented Gradients by Satya Mallick</a></p>

<p>[4] <a href="http://mccormickml.com/2013/05/07/gradient-vectors/">Gradient Vectors by Chris McCormick</a></p>

<p>[5] <a href="http://mccormickml.com/2013/05/09/hog-person-detector-tutorial/">HOG Person Detector Tutorial by Chris McCormick</a></p>
:ET