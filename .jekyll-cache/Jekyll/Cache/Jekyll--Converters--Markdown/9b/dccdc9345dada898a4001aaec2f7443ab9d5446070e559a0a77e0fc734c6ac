I"K=<div class="home other-pages">
  <ul class="post-list">
    
      <li>
        
        <span class="post-meta">
          Apr 8, 2018
          <span>
            
              
              <a class="post-tag" href="/lil-log/tag/reinforcement-learning"><nobr>reinforcement-learning</nobr>&nbsp;</a>
            
              
              <a class="post-tag" href="/lil-log/tag/review"><nobr>review</nobr>&nbsp;</a>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2018/04/08/policy-gradient-algorithms.html">Policy Gradient Algorithms</a>
          
            <blockquote>
  <p>Abstract: In this post, we are going to look deep into policy gradient, why it works, and many new policy gradient algorithms proposed in recent years: vanilla policy gradient, actor-critic, off-policy actor-critic, A3C, A2C, DPG, DDPG, MADDPG, TRPO, PPO, ACER, and ACTKR.</p>
</blockquote>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          Feb 19, 2018
          <span>
            
              
              <a class="post-tag" href="/lil-log/tag/reinforcement-learning"><nobr>reinforcement-learning</nobr>&nbsp;</a>
            
              
              <a class="post-tag" href="/lil-log/tag/review"><nobr>review</nobr>&nbsp;</a>
            
              
              <a class="post-tag" href="/lil-log/tag/long-read"><nobr>long-read</nobr>&nbsp;</a>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2018/02/19/a-long-peek-into-reinforcement-learning.html">A (Long) Peek into Reinforcement Learning</a>
          
            <blockquote>
  <p>In this post, we are gonna briefly go over the field of Reinforcement Learning (RL), from fundamental concepts to classic algorithms. Hopefully, this review is helpful enough so that newbies would not get lost in specialized terms and jargons while starting. [WARNING] This is a long read.</p>
</blockquote>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          Jan 23, 2018
          <span>
            
              
              <a class="post-tag" href="/lil-log/tag/reinforcement-learning"><nobr>reinforcement-learning</nobr>&nbsp;</a>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2018/01/23/the-multi-armed-bandit-problem-and-its-solutions.html">The Multi-Armed Bandit Problem and Its Solutions</a>
          
            <blockquote>
  <p>The multi-armed bandit problem is a classic example to demonstrate the exploration versus exploitation dilemma. This post introduces the bandit problem and how to solve it using different exploration strategies. The algorithms are implemented for Bernoulli bandit in <a href="https://github.com/lilianweng/multi-armed-bandit">lilianweng/multi-armed-bandit</a>.</p>
</blockquote>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          Jan 1, 2018
          <span>
            
              
              <a class="post-tag" href="/lil-log/tag/object-recognition"><nobr>object-recognition</nobr>&nbsp;</a>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2018/01/01/object-recognition-for-dummies-part-3.html">Object Recognition for Dummies Part 3: R-CNN and Fast/Faster/Mask R-CNN and YOLO</a>
          
            <blockquote>
  <p>In Part 3, we would examine five object recognition models: R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN and YOLO. These models are highly related and the new versions show great speed improvement compared to the older ones.</p>
</blockquote>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          Dec 16, 2017
          <span>
            
              
              <a class="post-tag" href="/lil-log/tag/object-recognition"><nobr>object-recognition</nobr>&nbsp;</a>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2017/12/16/object-recognition-for-dummies-part-2.html">Object Recognition for Dummies Part 2: CNN, DPM and Overfeat</a>
          
            <blockquote>
  <p>Part 2 introduces several classic convolutional neural work architecture designs for image classification (AlexNet, VGG, ResNet), as well as DPM (Deformable Parts Model) and Overfeat models for object recognition.</p>
</blockquote>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          Oct 29, 2017
          <span>
            
              
              <a class="post-tag" href="/lil-log/tag/object-recognition"><nobr>object-recognition</nobr>&nbsp;</a>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2017/10/29/object-recognition-for-dummies-part-1.html">Object Recognition for Dummies Part 1: Gradient Vector, HOG, and SS</a>
          
            <blockquote>
  <p>In this series of posts on “Object Recognition for Dummies”, we will go through several basic concepts, algorithms, and popular deep learning models for image processing and objection detection. Hopefully, it would be a good read for people with no experience in this field but want to learn more. The Part 1 introduces the concept of Gradient Vectors, the HOG (Histogram of Oriented Gradients) algorithm, and Selective Search for image segmentation.</p>
</blockquote>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          Oct 16, 2017
          <span>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2017/10/16/learning-word-embedding.html">Learning Word Embedding</a>
          
            <blockquote>
  <p>Word embedding is a dense representation of words in the form of numeric vectors. It can be learned using a variety of language models. The word embedding representation is able to reveal many hidden relationships between words. For example, vector(“cat”) - vector(“kitten”) is similar to vector(“dog”) - vector(“puppy”). This post introduces several models for learning word embedding and how their loss functions are designed for the purpose.</p>
</blockquote>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          Sep 29, 2017
          <span>
            
              
              <a class="post-tag" href="/lil-log/tag/information-theory"><nobr>information-theory</nobr>&nbsp;</a>
            
              
              <a class="post-tag" href="/lil-log/tag/review"><nobr>review</nobr>&nbsp;</a>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2017/09/29/anatomize-deep-learning-with-information-theory.html">Anatomize Deep Learning with Information Theory</a>
          
            <blockquote>
  <p>This post is a summary of Prof Naftali Tishby’s recent talk on <a href="https://youtu.be/bLqJHjXihK8">“Information Theory in Deep Learning”</a>. It presented how to apply the information theory to study the growth and transformation of deep neural networks during training.</p>
</blockquote>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          Aug 20, 2017
          <span>
            
              
              <a class="post-tag" href="/lil-log/tag/gan"><nobr>gan</nobr>&nbsp;</a>
            
              
              <a class="post-tag" href="/lil-log/tag/long-read"><nobr>long-read</nobr>&nbsp;</a>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2017/08/20/from-GAN-to-WGAN.html">From GAN to WGAN</a>
          
            <blockquote>
  <p>This post explains the maths behind a generative adversarial network (GAN) model and why it is hard to be trained. Wasserstein GAN is intended to improve GANs’ training by adopting a smooth metric for measuring the distance between two probability distributions.</p>
</blockquote>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          Aug 1, 2017
          <span>
            
              
              <a class="post-tag" href="/lil-log/tag/review"><nobr>review</nobr>&nbsp;</a>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2017/08/01/how-to-explain-the-prediction-of-a-machine-learning-model.html">How to Explain the Prediction of a Machine Learning Model?</a>
          
            <blockquote>
  <p>This post reviews some research in model interpretability, covering two aspects: (i) interpretable models with model-specific interpretation methods and (ii) approaches of explaining black-box models. I included an open discussion on explainable artificial intelligence at the end.</p>
</blockquote>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          Jul 22, 2017
          <span>
            
              
              <a class="post-tag" href="/lil-log/tag/rnn"><nobr>rnn</nobr>&nbsp;</a>
            
              
              <a class="post-tag" href="/lil-log/tag/tensorflow"><nobr>tensorflow</nobr>&nbsp;</a>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2017/07/22/predict-stock-prices-using-RNN-part-2.html">Predict Stock Prices Using RNN: Part 2</a>
          
            <blockquote>
  <p>This post is a continued tutorial for how to build a recurrent neural network using Tensorflow to predict stock market prices. Part 2 attempts to predict prices of multiple stocks using embeddings. The full working code is available in <a href="https://github.com/lilianweng/stock-rnn">github.com/lilianweng/stock-rnn</a>.</p>
</blockquote>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          Jul 8, 2017
          <span>
            
              
              <a class="post-tag" href="/lil-log/tag/rnn"><nobr>rnn</nobr>&nbsp;</a>
            
              
              <a class="post-tag" href="/lil-log/tag/tensorflow"><nobr>tensorflow</nobr>&nbsp;</a>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2017/07/08/predict-stock-prices-using-RNN-part-1.html">Predict Stock Prices Using RNN: Part 1</a>
          
            <blockquote>
  <p>This post is a tutorial for how to build a recurrent neural network using Tensorflow to predict stock market prices. Part 1 focuses on the prediction of S&amp;P 500 index. The full working code is available in <a href="https://github.com/lilianweng/stock-rnn">github.com/lilianweng/stock-rnn</a>.</p>
</blockquote>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          Jun 21, 2017
          <span>
            
              
              <a class="post-tag" href="/lil-log/tag/review"><nobr>review</nobr>&nbsp;</a>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2017/06/21/an-overview-of-deep-learning.html">An Overview of Deep Learning for Curious People</a>
          
            <blockquote>
  <p>Starting earlier this year, I grew a strong curiosity of deep learning and spent some time reading about this field. To document what I’ve learned and to provide some interesting pointers to people with similar interests, I wrote this overview of deep learning models and their applications.</p>
</blockquote>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          May 20, 2016
          <span>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2016/05/20/welcome-to-jekyll.html">Welcome To Jekyll</a>
          
            <p>You’ll find this post in your <code class="language-plaintext highlighter-rouge">_posts</code> directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run <code class="language-plaintext highlighter-rouge">jekyll serve</code>, which launches a web server and auto-regenerates your site when a file is updated.</p>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          May 20, 2016
          <span>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/junk/2016/05/20/this-post-demonstrates-post-content-styles.html">This post demonstrates post content styles</a>
          
            <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce bibendum neque eget nunc mattis eu sollicitudin enim tincidunt. Vestibulum lacus tortor, ultricies id dignissim ac, bibendum in velit.</p>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          May 20, 2016
          <span>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/misc/2016/05/20/super-long-article.html">Some articles are just so long they deserve a really long title to see if things will break well</a>
          
            <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce bibendum neque eget nunc mattis eu sollicitudin enim tincidunt. Vestibulum lacus tortor, ultricies id dignissim ac, bibendum in velit. Proin convallis mi ac felis pharetra aliquam. Curabitur dignissim accumsan rutrum. In arcu magna, aliquet vel pretium et, molestie et arcu. Mauris lobortis nulla et felis ullamcorper bibendum. Phasellus et hendrerit mauris. Proin eget nibh a massa vestibulum pretium. Suspendisse eu nisl a ante aliquet bibendum quis a nunc. Praesent varius interdum vehicula. Aenean risus libero, placerat at vestibulum eget, ultricies eu enim. Praesent nulla tortor, malesuada adipiscing adipiscing sollicitudin, adipiscing eget est.</p>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          May 20, 2016
          <span>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/2016/05/20/my-example-post.html">My Example Post</a>
          
            <p>Eos eu docendi tractatos sapientem, brute option menandri in vix, quando vivendo accommodare te ius. Nec melius fastidii constituam id, viderer theophrastus ad sit, hinc semper periculis cum id. Noluisse postulant assentior est in, no choro sadipscing repudiandae vix. Vis in euismod delenit dignissim. Ex quod nostrum sit, suas decore animal id ius, nobis solet detracto quo te.</p>

          
        </h2>
      </li>
    
      <li>
        
        <span class="post-meta">
          May 19, 2016
          <span>
            
          </span>
        </span>

        <h2>
          <a class="post-link" href="/misc/2016/05/19/super-short-article.html">Some articles are just so short that we have to make the footer stick</a>
          
            <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>

          
        </h2>
      </li>
    
  </ul>
 </div>
:ET